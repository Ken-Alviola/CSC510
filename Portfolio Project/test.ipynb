{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5e1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style()\n",
    "\n",
    "#from wrangle import wrangle_zillow, split_zillow\n",
    "#from scale_and_featureeng import select_kbest, rfe, scale_data\n",
    "\n",
    "#import explore\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def new_zillow_data():\n",
    "    '''\n",
    "    This function reads the zillow data from the Codeup db into a df,\n",
    "    write it to a csv file, and returns the df.\n",
    "    '''\n",
    "    # Create SQL query.\n",
    "    sql_query = ''' select parcelid, \n",
    "                        bathroomcnt, \n",
    "                        bedroomcnt,\n",
    "                        calculatedfinishedsquarefeet,\n",
    "                        fips,\n",
    "                        latitude,\n",
    "                        longitude,\n",
    "                        lotsizesquarefeet,\n",
    "                        regionidzip,\n",
    "                        yearbuilt,\n",
    "                        taxvaluedollarcnt,\n",
    "                        taxamount,\n",
    "                        transactiondate \n",
    "      from properties_2017\n",
    "      join predictions_2017 using(parcelid)\n",
    "      where transactiondate between \"2017-05-01\" and \"2017-08-31\"\n",
    "      AND (unitcnt = 1 OR propertylandusetypeid IN (261, 279, 262, 263, 264, 266, 275));\n",
    "                    '''\n",
    "    \n",
    "    # Read in DataFrame from Codeup db.\n",
    "    df = pd.read_sql(sql_query, get_connection('zillow'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_zillow_data(cached=False):\n",
    "    '''\n",
    "    This function reads in zillow data from Codeup database and writes data to\n",
    "    a csv file if cached == False or if cached == True reads in telco df from\n",
    "    a csv file, returns df.\n",
    "    '''\n",
    "    if cached == False or os.path.isfile('zillow.csv') == False:\n",
    "        \n",
    "        # Read fresh data from db into a DataFrame.\n",
    "        df = new_zillow_data()\n",
    "        \n",
    "        # Write DataFrame to a csv file.\n",
    "        df.to_csv('zillow.csv')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # If csv file exists or cached == True, read in data from csv.\n",
    "        df = pd.read_csv('zillow.csv', index_col=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def clean_zillow(df):\n",
    "    '''Takes in a df of zillow data and cleans the data by dropping null values, renaming columns, creating age column, and dealing with             outliers using 1.5x IQR    \n",
    "    \n",
    "    return: df, a cleaned pandas dataframe'''\n",
    "    \n",
    "    df = df.set_index('parcelid')  \n",
    "\n",
    "    df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df = df.rename(columns={\"bedroomcnt\": \"bedrooms\", \"bathroomcnt\": \"bathrooms\", \"calculatedfinishedsquarefeet\":    \n",
    "                                    \"square_feet\",\"taxamount\": \"taxes\", \"taxvaluedollarcnt\": \"tax_value\"})\n",
    "    \n",
    "    df['age_in_years'] = 2021 - df.yearbuilt\n",
    "    df['Bathrooms_cat'] = df.bathrooms.apply(lambda x: \"4+\" if x >= 4 else x)\n",
    "    df['Bedrooms_cat'] = df.bathrooms.apply(lambda x: \"4+\" if x >= 4 else x)\n",
    "    df['tax_rate'] = round(((df.taxes / df.tax_value) * 100), 2)\n",
    "    df = df.drop(columns=['yearbuilt']) \n",
    "    \n",
    "    q1 = df.tax_value.quantile(.25)\n",
    "    q3 = df.tax_value.quantile(.75)\n",
    "    iqr = q3 - q1\n",
    "    multiplier = 1.5\n",
    "    upper_bound = q3 + (multiplier * iqr)\n",
    "    lower_bound = q1 - (multiplier * iqr)\n",
    "    df = df[df.tax_value > lower_bound]\n",
    "    df = df[df.tax_value < upper_bound]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_zillow(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    train, validate, test split\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    if stratify_by == None:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "        train, validate = train_test_split(df, test_size=.3, random_state=123)\n",
    "    else:\n",
    "        train_validate, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "        train, validate = train_test_split(train_validate, test_size=.3, random_state=123, stratify=train_validate[stratify_by])\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "def wrangle_zillow(split=False):\n",
    "    '''\n",
    "    wrangle_zillow will read zillow.csv as a pandas dataframe,\n",
    "    clean the data\n",
    "    split the data\n",
    "    return: train, validate, test sets of pandas dataframes from zilow if split = True\n",
    "    '''\n",
    "    df = clean_zillow(get_zillow_data())\n",
    "    if split == True:\n",
    "        return split_zillow(df)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b50735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "\n",
    "def select_kbest(X, y, k):\n",
    "    f_selector = SelectKBest(f_regression, k)\n",
    "    f_selector.fit(X, y)\n",
    "    feature_mask = f_selector.get_support()\n",
    "\n",
    "    f_feature = X.iloc[:,feature_mask].columns.tolist()\n",
    "    return f_feature\n",
    "\n",
    "def rfe(X,y,k):\n",
    "    lm = LinearRegression()\n",
    "    rfe = RFE(lm,k)\n",
    "    rfe.fit(X, y)\n",
    "    feature_mask_rfe = rfe.support_\n",
    "    rfe_feature = X.iloc[:,feature_mask_rfe].columns.tolist()\n",
    "    return rfe_feature\n",
    "\n",
    "def scale_data(train,validate,test):\n",
    "    '''Accepts train, validate, test data frames and applies min-max scaler\n",
    "    return: train, validate, test scaled pandas dataframe'''\n",
    "    \n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(train)\n",
    "    \n",
    "    train_scaled = scaler.transform(train)\n",
    "    validate_scaled = scaler.transform(validate)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=train.columns)\n",
    "    validate_scaled = pd.DataFrame(validate_scaled, columns=train.columns)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=train.columns)\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e69a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "def explore_univariate(train, cat_vars, quant_vars):\n",
    "    for var in cat_vars:\n",
    "        explore_univariate_categorical(train, var)\n",
    "        print('_________________________________________________________________')\n",
    "    for col in quant_vars:\n",
    "        p, descriptive_stats = explore_univariate_quant(train, col)\n",
    "        plt.show(p)\n",
    "        print(descriptive_stats)\n",
    "        \n",
    "def explore_bivariate(train, target, cat_vars, quant_vars):\n",
    "    for cat in cat_vars:\n",
    "        explore_bivariate_categorical(train, target, cat)\n",
    "    for quant in quant_vars:\n",
    "        explore_bivariate_quant(train, target, quant)\n",
    "\n",
    "def explore_multivariate(train, target, cat_vars, quant_vars):\n",
    "    '''\n",
    "    '''\n",
    "    plot_swarm_grid_with_color(train, target, cat_vars, quant_vars)\n",
    "    plt.show()\n",
    "    violin = plot_violin_grid_with_color(train, target, cat_vars, quant_vars)\n",
    "    plt.show()\n",
    "    pair = sns.pairplot(data=train, vars=quant_vars, hue=target)\n",
    "    plt.show()\n",
    "    plot_all_continuous_vars(train, target, quant_vars)\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "### Univariate\n",
    "\n",
    "def explore_univariate_categorical(train, cat_var):\n",
    "    '''\n",
    "    takes in a dataframe and a categorical variable and returns\n",
    "    a frequency table and barplot of the frequencies. \n",
    "    '''\n",
    "    frequency_table = freq_table(train, cat_var)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.barplot(x=cat_var, y='Count', data=frequency_table, color='lightseagreen')\n",
    "    plt.title(cat_var)\n",
    "    plt.show()\n",
    "    print(frequency_table)\n",
    "\n",
    "def explore_univariate_quant(train, quant_var):\n",
    "    '''\n",
    "    takes in a dataframe and a quantitative variable and returns\n",
    "    descriptive stats table, histogram, and boxplot of the distributions. \n",
    "    '''\n",
    "    descriptive_stats = train[quant_var].describe()\n",
    "    plt.figure(figsize=(10,4))\n",
    "\n",
    "    p = plt.subplot(1, 2, 1)\n",
    "    p = plt.hist(train[quant_var], color='lightseagreen')\n",
    "    p = plt.title(quant_var)\n",
    "\n",
    "    # second plot: box plot\n",
    "    p = plt.subplot(1, 2, 2)\n",
    "    p = plt.boxplot(train[quant_var])\n",
    "    p = plt.title(quant_var)\n",
    "    return p, descriptive_stats\n",
    "    \n",
    "def freq_table(train, cat_var):\n",
    "    '''\n",
    "    for a given categorical variable, compute the frequency count and percent split\n",
    "    and return a dataframe of those values along with the different classes. \n",
    "    '''\n",
    "    class_labels = list(train[cat_var].unique())\n",
    "\n",
    "    frequency_table = (\n",
    "        pd.DataFrame({cat_var: class_labels,\n",
    "                      'Count': train[cat_var].value_counts(normalize=False), \n",
    "                      'Percent': round(train[cat_var].value_counts(normalize=True)*100,2)}\n",
    "                    )\n",
    "    )\n",
    "    return frequency_table\n",
    "\n",
    "\n",
    "#### Bivariate\n",
    "\n",
    "def explore_bivariate_categorical(train, target, cat_var):\n",
    "    '''\n",
    "    takes in categorical variable and binary target variable, \n",
    "    returns a crosstab of frequencies\n",
    "    runs a chi-square test for the proportions\n",
    "    and creates a barplot, adding a horizontal line of the overall rate of the target. \n",
    "    '''\n",
    "    print(cat_var, \"\\n_____________________\\n\")\n",
    "    ct = pd.crosstab(train[cat_var], train[target], margins=True)\n",
    "    chi2_summary, observed, expected = run_chi2(train, cat_var, target)\n",
    "    p = plot_cat_by_target(train, target, cat_var)\n",
    "    \n",
    "    print(chi2_summary)\n",
    "    print(\"\\nobserved:\\n\", ct)\n",
    "    print(\"\\nexpected:\\n\", expected)\n",
    "    plt.show(p)\n",
    "    print(\"\\n_____________________\\n\")\n",
    "\n",
    "def explore_bivariate_quant(train, target, quant_var):\n",
    "    '''\n",
    "    descriptive stats by each target class. \n",
    "    compare means across 2 target groups \n",
    "    boxenplot of target x quant\n",
    "    swarmplot of target x quant\n",
    "    '''\n",
    "    print(quant_var, \"\\n____________________\\n\")\n",
    "    descriptive_stats = train.groupby(target)[quant_var].describe()\n",
    "    average = train[quant_var].mean()\n",
    "    mann_whitney = compare_means(train, target, quant_var)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    boxen = plot_boxen(train, target, quant_var)\n",
    "    swarm = plot_swarm(train, target, quant_var)\n",
    "    plt.show()\n",
    "    print(descriptive_stats, \"\\n\")\n",
    "    print(\"\\nMann-Whitney Test:\\n\", mann_whitney)\n",
    "    print(\"\\n____________________\\n\")\n",
    "\n",
    "## Bivariate Categorical\n",
    "\n",
    "def run_chi2(train, cat_var, target):\n",
    "    observed = pd.crosstab(train[cat_var], train[target])\n",
    "    chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "    chi2_summary = pd.DataFrame({'chi2': [chi2], 'p-value': [p], \n",
    "                                 'degrees of freedom': [degf]})\n",
    "    expected = pd.DataFrame(expected)\n",
    "    return chi2_summary, observed, expected\n",
    "\n",
    "def plot_cat_by_target(train, target, cat_var):\n",
    "    p = plt.figure(figsize=(4,4))\n",
    "    p = sns.barplot(cat_var, target, data=train, alpha=.8, color='lightseagreen')\n",
    "    overall_rate = train[target].mean()\n",
    "    p = plt.axhline(overall_rate, ls='--', color='gray')\n",
    "    return p\n",
    "    \n",
    "\n",
    "## Bivariate Quant\n",
    "\n",
    "def plot_swarm(train, target, quant_var):\n",
    "    average = train[quant_var].mean()\n",
    "    p = sns.swarmplot(data=train, x=target, y=quant_var, color='lightgray')\n",
    "    p = plt.title(quant_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p\n",
    "\n",
    "def plot_boxen(train, target, quant_var):\n",
    "    average = train[quant_var].mean()\n",
    "    p = sns.boxenplot(data=train, x=target, y=quant_var, color='lightseagreen')\n",
    "    p = plt.title(quant_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p\n",
    "\n",
    "# alt_hyp = ‘two-sided’, ‘less’, ‘greater’\n",
    "\n",
    "def compare_means(train, target, quant_var, alt_hyp='two-sided'):\n",
    "    x = train[train[target]==0][quant_var]\n",
    "    y = train[train[target]==1][quant_var]\n",
    "    return stats.mannwhitneyu(x, y, use_continuity=True, alternative=alt_hyp)\n",
    "\n",
    "\n",
    "### Multivariate\n",
    "\n",
    "def plot_all_continuous_vars(train, target, quant_vars):\n",
    "    '''\n",
    "    Melt the dataset to \"long-form\" representation\n",
    "    boxenplot of measurement x value with color representing survived. \n",
    "    '''\n",
    "    my_vars = [item for sublist in [quant_vars, [target]] for item in sublist]\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "    melt = train[my_vars].melt(id_vars=target, var_name=\"measurement\")\n",
    "    plt.figure(figsize=(8,6))\n",
    "    p = sns.boxenplot(x=\"measurement\", y=\"value\", hue=target, data=melt)\n",
    "    p.set(yscale=\"log\", xlabel='')    \n",
    "    plt.show()\n",
    "\n",
    "def plot_violin_grid_with_color(train, target, cat_vars, quant_vars):\n",
    "    cols = len(cat_vars)\n",
    "    for quant in quant_vars:\n",
    "        _, ax = plt.subplots(nrows=1, ncols=cols, figsize=(16, 4), sharey=True)\n",
    "        for i, cat in enumerate(cat_vars):\n",
    "            sns.violinplot(x=cat, y=quant, data=train, split=True, \n",
    "                           ax=ax[i], hue=target, palette=\"Set2\")\n",
    "            ax[i].set_xlabel('')\n",
    "            ax[i].set_ylabel(quant)\n",
    "            ax[i].set_title(cat)\n",
    "        plt.show()\n",
    "    \n",
    "def plot_swarm_grid_with_color(train, target, cat_vars, quant_vars):\n",
    "    cols = len(cat_vars)\n",
    "    for quant in quant_vars:\n",
    "        _, ax = plt.subplots(nrows=1, ncols=cols, figsize=(16, 4), sharey=True)\n",
    "        for i, cat in enumerate(cat_vars):\n",
    "            sns.swarmplot(x=cat, y=quant, data=train, ax=ax[i], hue=target, palette=\"Set2\")\n",
    "            ax[i].set_xlabel('')\n",
    "            ax[i].set_ylabel(quant)\n",
    "            ax[i].set_title(cat)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9018b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
