{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5023bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style()\n",
    "\n",
    "#from wrangle import wrangle_zillow, split_zillow\n",
    "#from scale_and_featureeng import select_kbest, rfe, scale_data\n",
    "\n",
    "#import explore\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdf29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def new_zillow_data():\n",
    "    '''\n",
    "    This function reads the zillow data from the Codeup db into a df,\n",
    "    write it to a csv file, and returns the df.\n",
    "    '''\n",
    "    # Create SQL query.\n",
    "    sql_query = ''' select parcelid, \n",
    "                        bathroomcnt, \n",
    "                        bedroomcnt,\n",
    "                        calculatedfinishedsquarefeet,\n",
    "                        fips,\n",
    "                        latitude,\n",
    "                        longitude,\n",
    "                        lotsizesquarefeet,\n",
    "                        regionidzip,\n",
    "                        yearbuilt,\n",
    "                        taxvaluedollarcnt,\n",
    "                        taxamount,\n",
    "                        transactiondate \n",
    "      from properties_2017\n",
    "      join predictions_2017 using(parcelid)\n",
    "      where transactiondate between \"2017-05-01\" and \"2017-08-31\"\n",
    "      AND (unitcnt = 1 OR propertylandusetypeid IN (261, 279, 262, 263, 264, 266, 275));\n",
    "                    '''\n",
    "    \n",
    "    # Read in DataFrame from Codeup db.\n",
    "    df = pd.read_sql(sql_query, get_connection('zillow'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_zillow_data(cached=False):\n",
    "    '''\n",
    "    This function reads in zillow data from Codeup database and writes data to\n",
    "    a csv file if cached == False or if cached == True reads in telco df from\n",
    "    a csv file, returns df.\n",
    "    '''\n",
    "    if cached == False or os.path.isfile('zillow.csv') == False:\n",
    "        \n",
    "        # Read fresh data from db into a DataFrame.\n",
    "        df = new_zillow_data()\n",
    "        \n",
    "        # Write DataFrame to a csv file.\n",
    "        df.to_csv('zillow.csv')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # If csv file exists or cached == True, read in data from csv.\n",
    "        df = pd.read_csv('zillow.csv', index_col=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def clean_zillow(df):\n",
    "    '''Takes in a df of zillow data and cleans the data by dropping null values, renaming columns, creating age column,\n",
    "        and dealing with outliers using 1.5x IQR    \n",
    "    \n",
    "    return: df, a cleaned pandas dataframe'''\n",
    "    \n",
    "    df = df.set_index('parcelid')  \n",
    "\n",
    "    df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "    df = df.dropna()\n",
    "    df = df.rename(columns={\"bedroomcnt\": \"bedrooms\", \"bathroomcnt\": \"bathrooms\", \"calculatedfinishedsquarefeet\":    \n",
    "                                    \"square_feet\",\"taxamount\": \"taxes\", \"taxvaluedollarcnt\": \"tax_value\"})\n",
    "    \n",
    "    df['age_in_years'] = 2021 - df.yearbuilt\n",
    "    df['Bathrooms_cat'] = df.bathrooms.apply(lambda x: \"4+\" if x >= 4 else x)\n",
    "    df['Bedrooms_cat'] = df.bathrooms.apply(lambda x: \"4+\" if x >= 4 else x)\n",
    "    df['tax_rate'] = round(((df.taxes / df.tax_value) * 100), 2)\n",
    "    df = df.drop(columns=['yearbuilt']) \n",
    "    \n",
    "    q1 = df.tax_value.quantile(.25)\n",
    "    q3 = df.tax_value.quantile(.75)\n",
    "    iqr = q3 - q1\n",
    "    multiplier = 1.5\n",
    "    upper_bound = q3 + (multiplier * iqr)\n",
    "    lower_bound = q1 - (multiplier * iqr)\n",
    "    df = df[df.tax_value > lower_bound]\n",
    "    df = df[df.tax_value < upper_bound]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_zillow(df, stratify_by=None):\n",
    "    \"\"\"\n",
    "    train, validate, test split\n",
    "    To stratify, send in a column name\n",
    "    \"\"\"\n",
    "    \n",
    "    if stratify_by == None:\n",
    "        train, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "        train, validate = train_test_split(df, test_size=.3, random_state=123)\n",
    "    else:\n",
    "        train_validate, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[stratify_by])\n",
    "        train, validate = train_test_split(train_validate, test_size=.3, random_state=123, stratify=train_validate[stratify_by])\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "def wrangle_zillow(split=False):\n",
    "    '''\n",
    "    wrangle_zillow will read zillow.csv as a pandas dataframe,\n",
    "    clean the data\n",
    "    split the data\n",
    "    return: train, validate, test sets of pandas dataframes from zilow if split = True\n",
    "    '''\n",
    "    df = clean_zillow(get_zillow_data())\n",
    "    if split == True:\n",
    "        return split_zillow(df)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015368dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "\n",
    "def select_kbest(X, y, k):\n",
    "    f_selector = SelectKBest(f_regression, k)\n",
    "    f_selector.fit(X, y)\n",
    "    feature_mask = f_selector.get_support()\n",
    "\n",
    "    f_feature = X.iloc[:,feature_mask].columns.tolist()\n",
    "    return f_feature\n",
    "\n",
    "def rfe(X,y,k):\n",
    "    lm = LinearRegression()\n",
    "    rfe = RFE(lm,k)\n",
    "    rfe.fit(X, y)\n",
    "    feature_mask_rfe = rfe.support_\n",
    "    rfe_feature = X.iloc[:,feature_mask_rfe].columns.tolist()\n",
    "    return rfe_feature\n",
    "\n",
    "def scale_data(train,validate,test):\n",
    "    '''Accepts train, validate, test data frames and applies min-max scaler\n",
    "    return: train, validate, test scaled pandas dataframe'''\n",
    "    \n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    scaler.fit(train)\n",
    "    \n",
    "    train_scaled = scaler.transform(train)\n",
    "    validate_scaled = scaler.transform(validate)\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=train.columns)\n",
    "    validate_scaled = pd.DataFrame(validate_scaled, columns=train.columns)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=train.columns)\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963b565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "def explore_univariate(train, cat_vars, quant_vars):\n",
    "    for var in cat_vars:\n",
    "        explore_univariate_categorical(train, var)\n",
    "        print('_________________________________________________________________')\n",
    "    for col in quant_vars:\n",
    "        p, descriptive_stats = explore_univariate_quant(train, col)\n",
    "        plt.show(p)\n",
    "        print(descriptive_stats)\n",
    "        \n",
    "def explore_bivariate(train, target, cat_vars, quant_vars):\n",
    "    for cat in cat_vars:\n",
    "        explore_bivariate_categorical(train, target, cat)\n",
    "    for quant in quant_vars:\n",
    "        explore_bivariate_quant(train, target, quant)\n",
    "\n",
    "def explore_multivariate(train, target, cat_vars, quant_vars):\n",
    "    '''\n",
    "    '''\n",
    "    plot_swarm_grid_with_color(train, target, cat_vars, quant_vars)\n",
    "    plt.show()\n",
    "    violin = plot_violin_grid_with_color(train, target, cat_vars, quant_vars)\n",
    "    plt.show()\n",
    "    pair = sns.pairplot(data=train, vars=quant_vars, hue=target)\n",
    "    plt.show()\n",
    "    plot_all_continuous_vars(train, target, quant_vars)\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "### Univariate\n",
    "\n",
    "def explore_univariate_categorical(train, cat_var):\n",
    "    '''\n",
    "    takes in a dataframe and a categorical variable and returns\n",
    "    a frequency table and barplot of the frequencies. \n",
    "    '''\n",
    "    frequency_table = freq_table(train, cat_var)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.barplot(x=cat_var, y='Count', data=frequency_table, color='lightseagreen')\n",
    "    plt.title(cat_var)\n",
    "    plt.show()\n",
    "    print(frequency_table)\n",
    "\n",
    "def explore_univariate_quant(train, quant_var):\n",
    "    '''\n",
    "    takes in a dataframe and a quantitative variable and returns\n",
    "    descriptive stats table, histogram, and boxplot of the distributions. \n",
    "    '''\n",
    "    descriptive_stats = train[quant_var].describe()\n",
    "    plt.figure(figsize=(10,4))\n",
    "\n",
    "    p = plt.subplot(1, 2, 1)\n",
    "    p = plt.hist(train[quant_var], color='lightseagreen')\n",
    "    p = plt.title(quant_var)\n",
    "\n",
    "    # second plot: box plot\n",
    "    p = plt.subplot(1, 2, 2)\n",
    "    p = plt.boxplot(train[quant_var])\n",
    "    p = plt.title(quant_var)\n",
    "    return p, descriptive_stats\n",
    "    \n",
    "def freq_table(train, cat_var):\n",
    "    '''\n",
    "    for a given categorical variable, compute the frequency count and percent split\n",
    "    and return a dataframe of those values along with the different classes. \n",
    "    '''\n",
    "    class_labels = list(train[cat_var].unique())\n",
    "\n",
    "    frequency_table = (\n",
    "        pd.DataFrame({cat_var: class_labels,\n",
    "                      'Count': train[cat_var].value_counts(normalize=False), \n",
    "                      'Percent': round(train[cat_var].value_counts(normalize=True)*100,2)}\n",
    "                    )\n",
    "    )\n",
    "    return frequency_table\n",
    "\n",
    "\n",
    "#### Bivariate\n",
    "\n",
    "def explore_bivariate_categorical(train, target, cat_var):\n",
    "    '''\n",
    "    takes in categorical variable and binary target variable, \n",
    "    returns a crosstab of frequencies\n",
    "    runs a chi-square test for the proportions\n",
    "    and creates a barplot, adding a horizontal line of the overall rate of the target. \n",
    "    '''\n",
    "    print(cat_var, \"\\n_____________________\\n\")\n",
    "    ct = pd.crosstab(train[cat_var], train[target], margins=True)\n",
    "    chi2_summary, observed, expected = run_chi2(train, cat_var, target)\n",
    "    p = plot_cat_by_target(train, target, cat_var)\n",
    "    \n",
    "    print(chi2_summary)\n",
    "    print(\"\\nobserved:\\n\", ct)\n",
    "    print(\"\\nexpected:\\n\", expected)\n",
    "    plt.show(p)\n",
    "    print(\"\\n_____________________\\n\")\n",
    "\n",
    "def explore_bivariate_quant(train, target, quant_var):\n",
    "    '''\n",
    "    descriptive stats by each target class. \n",
    "    compare means across 2 target groups \n",
    "    boxenplot of target x quant\n",
    "    swarmplot of target x quant\n",
    "    '''\n",
    "    print(quant_var, \"\\n____________________\\n\")\n",
    "    descriptive_stats = train.groupby(target)[quant_var].describe()\n",
    "    average = train[quant_var].mean()\n",
    "    mann_whitney = compare_means(train, target, quant_var)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    boxen = plot_boxen(train, target, quant_var)\n",
    "    swarm = plot_swarm(train, target, quant_var)\n",
    "    plt.show()\n",
    "    print(descriptive_stats, \"\\n\")\n",
    "    print(\"\\nMann-Whitney Test:\\n\", mann_whitney)\n",
    "    print(\"\\n____________________\\n\")\n",
    "\n",
    "## Bivariate Categorical\n",
    "\n",
    "def run_chi2(train, cat_var, target):\n",
    "    observed = pd.crosstab(train[cat_var], train[target])\n",
    "    chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "    chi2_summary = pd.DataFrame({'chi2': [chi2], 'p-value': [p], \n",
    "                                 'degrees of freedom': [degf]})\n",
    "    expected = pd.DataFrame(expected)\n",
    "    return chi2_summary, observed, expected\n",
    "\n",
    "def plot_cat_by_target(train, target, cat_var):\n",
    "    p = plt.figure(figsize=(4,4))\n",
    "    p = sns.barplot(cat_var, target, data=train, alpha=.8, color='lightseagreen')\n",
    "    overall_rate = train[target].mean()\n",
    "    p = plt.axhline(overall_rate, ls='--', color='gray')\n",
    "    return p\n",
    "    \n",
    "\n",
    "## Bivariate Quant\n",
    "\n",
    "def plot_swarm(train, target, quant_var):\n",
    "    average = train[quant_var].mean()\n",
    "    p = sns.swarmplot(data=train, x=target, y=quant_var, color='lightgray')\n",
    "    p = plt.title(quant_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p\n",
    "\n",
    "def plot_boxen(train, target, quant_var):\n",
    "    average = train[quant_var].mean()\n",
    "    p = sns.boxenplot(data=train, x=target, y=quant_var, color='lightseagreen')\n",
    "    p = plt.title(quant_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p\n",
    "\n",
    "# alt_hyp = ‘two-sided’, ‘less’, ‘greater’\n",
    "\n",
    "def compare_means(train, target, quant_var, alt_hyp='two-sided'):\n",
    "    x = train[train[target]==0][quant_var]\n",
    "    y = train[train[target]==1][quant_var]\n",
    "    return stats.mannwhitneyu(x, y, use_continuity=True, alternative=alt_hyp)\n",
    "\n",
    "\n",
    "### Multivariate\n",
    "\n",
    "def plot_all_continuous_vars(train, target, quant_vars):\n",
    "    '''\n",
    "    Melt the dataset to \"long-form\" representation\n",
    "    boxenplot of measurement x value with color representing survived. \n",
    "    '''\n",
    "    my_vars = [item for sublist in [quant_vars, [target]] for item in sublist]\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "    melt = train[my_vars].melt(id_vars=target, var_name=\"measurement\")\n",
    "    plt.figure(figsize=(8,6))\n",
    "    p = sns.boxenplot(x=\"measurement\", y=\"value\", hue=target, data=melt)\n",
    "    p.set(yscale=\"log\", xlabel='')    \n",
    "    plt.show()\n",
    "\n",
    "def plot_violin_grid_with_color(train, target, cat_vars, quant_vars):\n",
    "    cols = len(cat_vars)\n",
    "    for quant in quant_vars:\n",
    "        _, ax = plt.subplots(nrows=1, ncols=cols, figsize=(16, 4), sharey=True)\n",
    "        for i, cat in enumerate(cat_vars):\n",
    "            sns.violinplot(x=cat, y=quant, data=train, split=True, \n",
    "                           ax=ax[i], hue=target, palette=\"Set2\")\n",
    "            ax[i].set_xlabel('')\n",
    "            ax[i].set_ylabel(quant)\n",
    "            ax[i].set_title(cat)\n",
    "        plt.show()\n",
    "    \n",
    "def plot_swarm_grid_with_color(train, target, cat_vars, quant_vars):\n",
    "    cols = len(cat_vars)\n",
    "    for quant in quant_vars:\n",
    "        _, ax = plt.subplots(nrows=1, ncols=cols, figsize=(16, 4), sharey=True)\n",
    "        for i, cat in enumerate(cat_vars):\n",
    "            sns.swarmplot(x=cat, y=quant, data=train, ax=ax[i], hue=target, palette=\"Set2\")\n",
    "            ax[i].set_xlabel('')\n",
    "            ax[i].set_ylabel(quant)\n",
    "            ax[i].set_title(cat)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256aa0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimNumber</th>\n",
       "      <th>DateTimeOfAccident</th>\n",
       "      <th>DateReported</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>DependentChildren</th>\n",
       "      <th>DependentsOther</th>\n",
       "      <th>WeeklyWages</th>\n",
       "      <th>PartTimeFullTime</th>\n",
       "      <th>HoursWorkedPerWeek</th>\n",
       "      <th>DaysWorkedPerWeek</th>\n",
       "      <th>ClaimDescription</th>\n",
       "      <th>InitialIncurredCalimsCost</th>\n",
       "      <th>UltimateIncurredClaimCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WC8285054</td>\n",
       "      <td>2002-04-09T07:00:00Z</td>\n",
       "      <td>2002-07-05T00:00:00Z</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>F</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>LIFTING TYRE INJURY TO RIGHT ARM AND WRIST INJURY</td>\n",
       "      <td>1500</td>\n",
       "      <td>4748.203388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WC6982224</td>\n",
       "      <td>1999-01-07T11:00:00Z</td>\n",
       "      <td>1999-01-20T00:00:00Z</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>509.34</td>\n",
       "      <td>F</td>\n",
       "      <td>37.5</td>\n",
       "      <td>5</td>\n",
       "      <td>STEPPED AROUND CRATES AND TRUCK TRAY FRACTURE ...</td>\n",
       "      <td>5500</td>\n",
       "      <td>6326.285819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WC5481426</td>\n",
       "      <td>1996-03-25T00:00:00Z</td>\n",
       "      <td>1996-04-14T00:00:00Z</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>709.10</td>\n",
       "      <td>F</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>CUT ON SHARP EDGE CUT LEFT THUMB</td>\n",
       "      <td>1700</td>\n",
       "      <td>2293.949087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WC9775968</td>\n",
       "      <td>2005-06-22T13:00:00Z</td>\n",
       "      <td>2005-07-22T00:00:00Z</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>555.46</td>\n",
       "      <td>F</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>DIGGING LOWER BACK LOWER BACK STRAIN</td>\n",
       "      <td>15000</td>\n",
       "      <td>17786.487170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WC2634037</td>\n",
       "      <td>1990-08-29T08:00:00Z</td>\n",
       "      <td>1990-09-27T00:00:00Z</td>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377.10</td>\n",
       "      <td>F</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>REACHING ABOVE SHOULDER LEVEL ACUTE MUSCLE STR...</td>\n",
       "      <td>2800</td>\n",
       "      <td>4014.002925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ClaimNumber    DateTimeOfAccident          DateReported  Age Gender  \\\n",
       "0   WC8285054  2002-04-09T07:00:00Z  2002-07-05T00:00:00Z   48      M   \n",
       "1   WC6982224  1999-01-07T11:00:00Z  1999-01-20T00:00:00Z   43      F   \n",
       "2   WC5481426  1996-03-25T00:00:00Z  1996-04-14T00:00:00Z   30      M   \n",
       "3   WC9775968  2005-06-22T13:00:00Z  2005-07-22T00:00:00Z   41      M   \n",
       "4   WC2634037  1990-08-29T08:00:00Z  1990-09-27T00:00:00Z   36      M   \n",
       "\n",
       "  MaritalStatus  DependentChildren  DependentsOther  WeeklyWages  \\\n",
       "0             M                  0                0       500.00   \n",
       "1             M                  0                0       509.34   \n",
       "2             U                  0                0       709.10   \n",
       "3             S                  0                0       555.46   \n",
       "4             M                  0                0       377.10   \n",
       "\n",
       "  PartTimeFullTime  HoursWorkedPerWeek  DaysWorkedPerWeek  \\\n",
       "0                F                38.0                  5   \n",
       "1                F                37.5                  5   \n",
       "2                F                38.0                  5   \n",
       "3                F                38.0                  5   \n",
       "4                F                38.0                  5   \n",
       "\n",
       "                                    ClaimDescription  \\\n",
       "0  LIFTING TYRE INJURY TO RIGHT ARM AND WRIST INJURY   \n",
       "1  STEPPED AROUND CRATES AND TRUCK TRAY FRACTURE ...   \n",
       "2                   CUT ON SHARP EDGE CUT LEFT THUMB   \n",
       "3               DIGGING LOWER BACK LOWER BACK STRAIN   \n",
       "4  REACHING ABOVE SHOULDER LEVEL ACUTE MUSCLE STR...   \n",
       "\n",
       "   InitialIncurredCalimsCost  UltimateIncurredClaimCost  \n",
       "0                       1500                4748.203388  \n",
       "1                       5500                6326.285819  \n",
       "2                       1700                2293.949087  \n",
       "3                      15000               17786.487170  \n",
       "4                       2800                4014.002925  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8722b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54000 entries, 0 to 53999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   ClaimNumber                54000 non-null  object \n",
      " 1   DateTimeOfAccident         54000 non-null  object \n",
      " 2   DateReported               54000 non-null  object \n",
      " 3   Age                        54000 non-null  int64  \n",
      " 4   Gender                     54000 non-null  object \n",
      " 5   MaritalStatus              53971 non-null  object \n",
      " 6   DependentChildren          54000 non-null  int64  \n",
      " 7   DependentsOther            54000 non-null  int64  \n",
      " 8   WeeklyWages                54000 non-null  float64\n",
      " 9   PartTimeFullTime           54000 non-null  object \n",
      " 10  HoursWorkedPerWeek         54000 non-null  float64\n",
      " 11  DaysWorkedPerWeek          54000 non-null  int64  \n",
      " 12  ClaimDescription           54000 non-null  object \n",
      " 13  InitialIncurredCalimsCost  54000 non-null  int64  \n",
      " 14  UltimateIncurredClaimCost  54000 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4ab6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DependentChildren</th>\n",
       "      <th>DependentsOther</th>\n",
       "      <th>WeeklyWages</th>\n",
       "      <th>HoursWorkedPerWeek</th>\n",
       "      <th>DaysWorkedPerWeek</th>\n",
       "      <th>InitialIncurredCalimsCost</th>\n",
       "      <th>UltimateIncurredClaimCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54000.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "      <td>5.400000e+04</td>\n",
       "      <td>5.400000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.842370</td>\n",
       "      <td>0.119185</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>416.364807</td>\n",
       "      <td>37.735084</td>\n",
       "      <td>4.905759</td>\n",
       "      <td>7.841146e+03</td>\n",
       "      <td>1.100337e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.122165</td>\n",
       "      <td>0.517780</td>\n",
       "      <td>0.109348</td>\n",
       "      <td>248.638669</td>\n",
       "      <td>12.568704</td>\n",
       "      <td>0.552129</td>\n",
       "      <td>2.058408e+04</td>\n",
       "      <td>3.339099e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.218868e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000e+02</td>\n",
       "      <td>9.263384e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>392.200000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>3.371242e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.500000e+03</td>\n",
       "      <td>8.197249e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7497.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>4.027136e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  DependentChildren  DependentsOther   WeeklyWages  \\\n",
       "count  54000.000000       54000.000000     54000.000000  54000.000000   \n",
       "mean      33.842370           0.119185         0.009944    416.364807   \n",
       "std       12.122165           0.517780         0.109348    248.638669   \n",
       "min       13.000000           0.000000         0.000000      1.000000   \n",
       "25%       23.000000           0.000000         0.000000    200.000000   \n",
       "50%       32.000000           0.000000         0.000000    392.200000   \n",
       "75%       43.000000           0.000000         0.000000    500.000000   \n",
       "max       81.000000           9.000000         5.000000   7497.000000   \n",
       "\n",
       "       HoursWorkedPerWeek  DaysWorkedPerWeek  InitialIncurredCalimsCost  \\\n",
       "count        54000.000000       54000.000000               5.400000e+04   \n",
       "mean            37.735084           4.905759               7.841146e+03   \n",
       "std             12.568704           0.552129               2.058408e+04   \n",
       "min              0.000000           1.000000               1.000000e+00   \n",
       "25%             38.000000           5.000000               7.000000e+02   \n",
       "50%             38.000000           5.000000               2.000000e+03   \n",
       "75%             40.000000           5.000000               9.500000e+03   \n",
       "max            640.000000           7.000000               2.000000e+06   \n",
       "\n",
       "       UltimateIncurredClaimCost  \n",
       "count               5.400000e+04  \n",
       "mean                1.100337e+04  \n",
       "std                 3.339099e+04  \n",
       "min                 1.218868e+02  \n",
       "25%                 9.263384e+02  \n",
       "50%                 3.371242e+03  \n",
       "75%                 8.197249e+03  \n",
       "max                 4.027136e+06  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88b22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
